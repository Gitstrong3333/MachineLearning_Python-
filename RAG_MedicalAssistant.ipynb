{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gitstrong3333/MachineLearning_Python-/blob/main/RAG_MedicalAssistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD0PsYEUGcwM",
        "outputId": "fc7ac3ec-02ba-4b43-9b1c-5656dd93be4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BTgtLh_kGh9w",
        "outputId": "f31be133-a3da-4724-952f-a1e790b0a959"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16412,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14984,\n        \"samples\": [\n          \"How many people are affected by 8p11 myeloproliferative syndrome ?\",\n          \"What is (are) caudal regression syndrome ?\",\n          \"What is the outlook for Cephalic Disorders ?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15817,\n        \"samples\": [\n          \"The prognosis depends upon the severity of symptoms. Children with early-onset AGS have the highest risk of death. Children with the later-onset form may be left with weakness or stiffness in the peripheral muscles and arms, weak muscles in the trunk of the body, and poor head control. Almost all children with AGS have mild to severe intellectual and physical impairment.\",\n          \"Scientists don't know exactly what causes prostate cancer. They cannot explain why one man gets prostate cancer and another does not. However, they have been able to identify some risk factors that are associated with the disease. A risk factor is anything that increases your chances of getting a disease. Age Age is the most important risk factor for prostate cancer. The disease is extremely rare in men under age 40, but the risk increases greatly with age. More than 60 percent of cases are diagnosed in men over age 65. The average age at the time of diagnosis is 65. Race Race is another major risk factor. In the United States, this disease is much more common in African American men than in any other group of men. It is least common in Asian and American Indian men. Family History A man's risk for developing prostate cancer is higher if his father or brother has had the disease. Other Risk Factors Scientists have wondered whether obesity, lack of exercise, smoking, radiation exposure, might increase risk. But at this time, there is no firm evidence that these factors contribute to an increased risk.\",\n          \"The retina is a layer of tissue in the back of your eye that senses light and sends images to your brain. It provides the sharp, central vision needed for reading, driving, and seeing fine detail. A retinal detachment lifts or pulls the retina from its normal position. It can occur at any age, but it is more common in people over age 40. It affects men more than women and whites more than African Americans. A retinal detachment is also more likely to occur in people who       - Are extremely nearsighted    - Have had a retinal detachment in the other eye    - Have a family history of retinal detachment    - Have had cataract surgery    - Have other eye diseases or disorders    - Have had an eye injury       Symptoms include an increase in the number of floaters, which are little \\\"cobwebs\\\" or specks that float about in your field of vision, and/or light flashes in the eye. It may also seem like there is a \\\"curtain\\\" over your field of vision.    A retinal detachment is a medical emergency. If not promptly treated, it can cause permanent vision loss. If you have any symptoms, see an eye care professional immediately. Treatment includes different types of surgery.    NIH: National Eye Institute\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"GHR\",\n          \"CancerGov\",\n          \"NHLBI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"focus_area\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5126,\n        \"samples\": [\n          \"Adams-Oliver syndrome\",\n          \"Occupational Health\",\n          \"What I need to know about Diverticular Disease\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-edcfde38-aff9-482c-a6b7-5751e312d0a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>source</th>\n",
              "      <th>focus_area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is (are) Glaucoma ?</td>\n",
              "      <td>Glaucoma is a group of diseases that can damag...</td>\n",
              "      <td>NIHSeniorHealth</td>\n",
              "      <td>Glaucoma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What causes Glaucoma ?</td>\n",
              "      <td>Nearly 2.7 million people have glaucoma, a lea...</td>\n",
              "      <td>NIHSeniorHealth</td>\n",
              "      <td>Glaucoma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are the symptoms of Glaucoma ?</td>\n",
              "      <td>Symptoms of Glaucoma  Glaucoma can develop in ...</td>\n",
              "      <td>NIHSeniorHealth</td>\n",
              "      <td>Glaucoma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are the treatments for Glaucoma ?</td>\n",
              "      <td>Although open-angle glaucoma cannot be cured, ...</td>\n",
              "      <td>NIHSeniorHealth</td>\n",
              "      <td>Glaucoma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is (are) Glaucoma ?</td>\n",
              "      <td>Glaucoma is a group of diseases that can damag...</td>\n",
              "      <td>NIHSeniorHealth</td>\n",
              "      <td>Glaucoma</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edcfde38-aff9-482c-a6b7-5751e312d0a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-edcfde38-aff9-482c-a6b7-5751e312d0a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-edcfde38-aff9-482c-a6b7-5751e312d0a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1f647d96-2e95-40fc-8acf-7baffff36d95\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f647d96-2e95-40fc-8acf-7baffff36d95')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1f647d96-2e95-40fc-8acf-7baffff36d95 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                 question  \\\n",
              "0                What is (are) Glaucoma ?   \n",
              "1                  What causes Glaucoma ?   \n",
              "2     What are the symptoms of Glaucoma ?   \n",
              "3  What are the treatments for Glaucoma ?   \n",
              "4                What is (are) Glaucoma ?   \n",
              "\n",
              "                                              answer           source  \\\n",
              "0  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n",
              "1  Nearly 2.7 million people have glaucoma, a lea...  NIHSeniorHealth   \n",
              "2  Symptoms of Glaucoma  Glaucoma can develop in ...  NIHSeniorHealth   \n",
              "3  Although open-angle glaucoma cannot be cured, ...  NIHSeniorHealth   \n",
              "4  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n",
              "\n",
              "  focus_area  \n",
              "0   Glaucoma  \n",
              "1   Glaucoma  \n",
              "2   Glaucoma  \n",
              "3   Glaucoma  \n",
              "4   Glaucoma  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/medquad.csv'  # adjust if it's in a subfolder\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "6xJv1tYCNYEH",
        "outputId": "17ef8d1a-b2cb-4d5f-b523-c19af335e289"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          14984,\n          \"20\",\n          \"16412\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          15817,\n          \"348\",\n          \"16407\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          9,\n          \"5430\",\n          \"16412\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"focus_area\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5126,\n          \"53\",\n          \"16398\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-78a70eb9-74a3-4664-83a2-6f33fa73f935\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>source</th>\n",
              "      <th>focus_area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16412</td>\n",
              "      <td>16407</td>\n",
              "      <td>16412</td>\n",
              "      <td>16398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>14984</td>\n",
              "      <td>15817</td>\n",
              "      <td>9</td>\n",
              "      <td>5126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>What causes Causes of Diabetes ?</td>\n",
              "      <td>This condition is inherited in an autosomal re...</td>\n",
              "      <td>GHR</td>\n",
              "      <td>Breast Cancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>20</td>\n",
              "      <td>348</td>\n",
              "      <td>5430</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78a70eb9-74a3-4664-83a2-6f33fa73f935')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78a70eb9-74a3-4664-83a2-6f33fa73f935 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78a70eb9-74a3-4664-83a2-6f33fa73f935');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bc021522-86c0-4aa6-9ce7-fe21a1f73e40\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bc021522-86c0-4aa6-9ce7-fe21a1f73e40')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bc021522-86c0-4aa6-9ce7-fe21a1f73e40 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                question  \\\n",
              "count                              16412   \n",
              "unique                             14984   \n",
              "top     What causes Causes of Diabetes ?   \n",
              "freq                                  20   \n",
              "\n",
              "                                                   answer source  \\\n",
              "count                                               16407  16412   \n",
              "unique                                              15817      9   \n",
              "top     This condition is inherited in an autosomal re...    GHR   \n",
              "freq                                                  348   5430   \n",
              "\n",
              "           focus_area  \n",
              "count           16398  \n",
              "unique           5126  \n",
              "top     Breast Cancer  \n",
              "freq               53  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VZPBhGTHKMs"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import argparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "class RAGDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset class for loading query-context-answer pairs for training the RAG model.\n",
        "    This class handles tokenizing the data and preparing it for PyTorch's DataLoader.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframe, tokenizer, source_len, target_len):\n",
        "        \"\"\"\n",
        "        Initialize the dataset.\n",
        "\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): The dataset containing query, context, and answer columns.\n",
        "            tokenizer (transformers.PreTrainedTokenizer): Tokenizer for encoding text.\n",
        "            source_len (int): Maximum length for the input sequence.\n",
        "            target_len (int): Maximum length for the target sequence.\n",
        "        \"\"\"\n",
        "        self.data = dataframe.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.source_len = source_len\n",
        "        self.target_len = target_len\n",
        "        self.query = self.data['query']\n",
        "        self.context = self.data['context']\n",
        "        self.answer = self.data['answer']\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            int: The number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieve a single data point from the dataset.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the data point.\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary containing tokenized input and target sequences.\n",
        "        \"\"\"\n",
        "        query = str(self.query[idx])\n",
        "        context = str(self.context[idx])\n",
        "        answer = str(self.answer[idx])\n",
        "\n",
        "        # combine query and context into a single input string\n",
        "        source_text = f\"query: {query} context: {context}\"\n",
        "\n",
        "        # tokenize the input string\n",
        "        source = self.tokenizer.encode_plus(\n",
        "            source_text, max_length=self.source_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
        "        )\n",
        "        # tokenize the answer string\n",
        "        target = self.tokenizer.encode_plus(\n",
        "            answer, max_length=self.target_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": source[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": source[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": target[\"input_ids\"].squeeze(),\n",
        "        }\n",
        "\n",
        "\n",
        "def preprocess_data(file_path):\n",
        "    \"\"\"\n",
        "    Preprocess the dataset to include required columns and handle missing values.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the dataset CSV file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Preprocessed dataframe with 'query', 'context', and 'answer' columns.\n",
        "    \"\"\"\n",
        "    # load the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # retain only the 'question' and 'answer' columns\n",
        "    df = df[['question', 'answer']]\n",
        "\n",
        "    # drop rows with missing values\n",
        "    df = df.dropna(subset=['question', 'answer'])\n",
        "\n",
        "    # rename columns for consistency\n",
        "    df = df.rename(columns={'question': 'query', 'answer': 'answer'})\n",
        "\n",
        "    # add a 'context' column (using the answer as context for now)\n",
        "    df['context'] = df['answer']\n",
        "    return df\n",
        "\n",
        "\n",
        "def train_epoch(model, loader, optimizer, device, epoch, logging_steps):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model being trained.\n",
        "        loader (DataLoader): DataLoader for the training data.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer for updating model weights.\n",
        "        device (torch.device): Device to run the model on (CPU, GPU, etc.).\n",
        "        epoch (int): Current epoch number.\n",
        "        logging_steps (int): Frequency of logging progress during training.\n",
        "\n",
        "    Returns:\n",
        "        float: The average training loss for the epoch.\n",
        "    \"\"\"\n",
        "    model.train()  # set the model to training mode\n",
        "    total_loss = 0  # initialize total loss\n",
        "    progress_bar = tqdm(loader, desc=f\"Epoch {epoch}\", disable=False)  # progress bar for tracking\n",
        "\n",
        "    for step, batch in enumerate(progress_bar):\n",
        "        # move inputs and labels to the specified device\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        # forward pass through the model\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # backward pass and optimization step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # log the loss every `logging_steps`\n",
        "        if (step + 1) % logging_steps == 0:\n",
        "            progress_bar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "    # return the average loss for the epoch\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to fine-tune the T5 model for Retrieval-Augmented Generation (RAG).\n",
        "    This version handles Jupyter Notebook's extra arguments gracefully.\n",
        "    \"\"\"\n",
        "    # simulating command-line arguments for Jupyter Notebook\n",
        "    class Args:\n",
        "        model_name = \"t5-base\"\n",
        "        train_file = \"/content/drive/MyDrive/medquad.csv\"\n",
        "        output_dir = \"rag_model\"\n",
        "        batch_size = 8\n",
        "        epochs = 3\n",
        "        lr = 5e-5\n",
        "        max_input_length = 512\n",
        "        max_output_length = 150\n",
        "        device = \"cuda\"\n",
        "        logging_steps = 10\n",
        "\n",
        "    args = Args()  # use the custom Args class to store arguments\n",
        "\n",
        "    # enhanced device selection logic\n",
        "    if args.device == \"mps\" and torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "    elif args.device == \"cuda\" and torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # preprocess the data\n",
        "    df = preprocess_data(args.train_file)\n",
        "\n",
        "    # split data into training and validation sets\n",
        "    train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "\n",
        "    # load the tokenizer and model\n",
        "    tokenizer = T5Tokenizer.from_pretrained(args.model_name, legacy=False)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(args.model_name).to(device)\n",
        "\n",
        "    # create DataLoaders for training and validation datasets\n",
        "    train_dataset = RAGDataset(train_df, tokenizer, args.max_input_length, args.max_output_length)\n",
        "    val_dataset = RAGDataset(val_df, tokenizer, args.max_input_length, args.max_output_length)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    # optimizer\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
        "\n",
        "    # training loop\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, device, epoch, args.logging_steps)\n",
        "        print(f\"Epoch {epoch} Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # save the model and tokenizer\n",
        "    model.save_pretrained(args.output_dir)\n",
        "    tokenizer.save_pretrained(args.output_dir)\n",
        "    print(f\"Model saved to {args.output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JunnPhUEHlec",
        "outputId": "4e906bc1-d37b-4f33-cbc5-339866172209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No 'context' column found. Creating it from the 'answer' column.\n",
            "Updated dataset with 'context' column saved to /content/drive/MyDrive/medquad_out.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index saved to /content/drive/MyDrive/context.index\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# define parameters\n",
        "csv_file = \"/content/drive/MyDrive/medquad.csv\"  # path to your dataset\n",
        "updated_csv_file = \"/content/drive/MyDrive/medquad_out.csv\" # output dataset path\n",
        "index_file = \"/content/drive/MyDrive/context.index\"  # path to save the FAISS index\n",
        "\n",
        "# load the dataset\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# add a 'context' column if it doesn't exist\n",
        "if 'context' not in df.columns:\n",
        "    print(\"No 'context' column found. Creating it from the 'answer' column.\")\n",
        "    if 'answer' not in df.columns:\n",
        "        raise ValueError(\"The dataset must have an 'answer' column to create the 'context'.\")\n",
        "    df['context'] = df['answer']  # use 'answer' as the context\n",
        "\n",
        "# save the updated dataset with the 'context' column\n",
        "df.to_csv(updated_csv_file, index=False)\n",
        "print(f\"Updated dataset with 'context' column saved to {updated_csv_file}\")\n",
        "\n",
        "# use SentenceTransformer to generate embeddings for the context column\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "contexts = df[\"context\"].tolist()\n",
        "context_embeddings = embedder.encode(contexts, convert_to_tensor=False).astype(\"float32\")\n",
        "\n",
        "# create a FAISS index for the embeddings\n",
        "dimension = context_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 (Euclidean) distance\n",
        "index.add(context_embeddings)\n",
        "\n",
        "# save the FAISS index\n",
        "faiss.write_index(index, index_file)\n",
        "print(f\"FAISS index saved to {index_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# RAG: Build/Load Index + Generate Answers with T5\n",
        "# =========================\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "CSV_IN         = \"/content/drive/MyDrive/medquad.csv\"                 # original dataset\n",
        "CSV_WITH_CTX   = \"/content/drive/MyDrive/medquad_with_context.csv\"    # output with 'context'\n",
        "INDEX_PATH     = \"/content/drive/MyDrive/context.index\"               # FAISS index path\n",
        "\n",
        "# Model: use a real public model id (safe, no login)\n",
        "MODEL_ID       = \"google/flan-t5-base\"  # or \"t5-small\" for speed\n",
        "\n",
        "# Retrieval settings\n",
        "TOP_K          = 3\n",
        "MAX_NEW_TOKENS = 150\n",
        "NUM_BEAMS      = 5\n",
        "\n",
        "# Device selection (cuda, mps, or cpu)\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ---------- 1) LOAD/CREATE DATA WITH 'context' ----------\n",
        "def ensure_context(csv_in: str, csv_out: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_in)\n",
        "    if 'context' not in df.columns:\n",
        "        print(\"No 'context' column found. Creating it from the 'answer' column.\")\n",
        "        if 'answer' not in df.columns:\n",
        "            raise ValueError(\"Dataset must have an 'answer' column to create 'context'.\")\n",
        "        df['context'] = df['answer'].astype(str)\n",
        "    else:\n",
        "        df['context'] = df['context'].astype(str)\n",
        "    df.to_csv(csv_out, index=False)\n",
        "    print(f\"Saved dataset with 'context'  {csv_out} (rows: {len(df)})\")\n",
        "    return df\n",
        "\n",
        "df = ensure_context(CSV_IN, CSV_WITH_CTX)\n",
        "\n",
        "# ---------- 2) EMBEDDINGS + INDEX (build if missing) ----------\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def build_faiss_index(texts: list[str], index_path: str) -> faiss.Index:\n",
        "    # Cosine-friendly: normalize + Inner Product index\n",
        "    emb = embedder.encode(\n",
        "        texts,\n",
        "        batch_size=64,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True,  # unit vectors => cosine == inner product\n",
        "        show_progress_bar=True\n",
        "    ).astype(\"float32\")\n",
        "\n",
        "    d = emb.shape[1]\n",
        "    index = faiss.IndexFlatIP(d)\n",
        "    index.add(np.ascontiguousarray(emb))\n",
        "    faiss.write_index(index, index_path)\n",
        "    print(f\"Built & saved FAISS index ({index.ntotal} vectors, dim={d})  {index_path}\")\n",
        "    return index\n",
        "\n",
        "def load_or_build_index(index_path: str, texts: list[str]) -> faiss.Index:\n",
        "    if os.path.exists(index_path):\n",
        "        index = faiss.read_index(index_path)\n",
        "        print(f\"Loaded FAISS index from {index_path} (ntotal={index.ntotal})\")\n",
        "        return index\n",
        "    else:\n",
        "        return build_faiss_index(texts, index_path)\n",
        "\n",
        "index = load_or_build_index(INDEX_PATH, df[\"context\"].tolist())\n",
        "\n",
        "# ---------- 3) RETRIEVAL ----------\n",
        "def retrieve_contexts(query: str, index: faiss.Index, df: pd.DataFrame, top_k: int = 3) -> list[str]:\n",
        "    # Encode query\n",
        "    qv = embedder.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
        "    qv = np.ascontiguousarray(qv)\n",
        "\n",
        "    # If index is Inner Product (cosine), normalize the query too.\n",
        "    # (Index types with a `metric_type` attr report it; for older FAISS, try/except.)\n",
        "    metric_ip = False\n",
        "    try:\n",
        "        metric_ip = getattr(index, \"metric_type\", None) == faiss.METRIC_INNER_PRODUCT\n",
        "    except Exception:\n",
        "        pass\n",
        "    if metric_ip:\n",
        "        faiss.normalize_L2(qv)\n",
        "\n",
        "    distances, indices = index.search(qv, top_k)\n",
        "    hits = []\n",
        "    for i in indices[0]:\n",
        "        if i >= 0 and i < len(df):\n",
        "            hits.append(df.iloc[i][\"context\"])\n",
        "    return hits\n",
        "\n",
        "# ---------- 4) LOAD GENERATION MODEL ----------\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_ID, legacy=False)\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_ID).to(device)\n",
        "model.eval()\n",
        "\n",
        "# ---------- 5) RAG INFERENCE ----------\n",
        "def answer_query(query: str, top_k: int = 3) -> dict:\n",
        "    contexts = retrieve_contexts(query, index, df, top_k=top_k)\n",
        "    # Stronger instruction to list symptoms from context\n",
        "    input_text = (\n",
        "        \"You are a concise medical assistant.\\n\"\n",
        "        \"Using ONLY the context, list the common symptoms of diabetes as bullet points.\\n\"\n",
        "        \"If something isn't in the context, do not include it.\\n\"\n",
        "        f\"Question: {query}\\n\"\n",
        "        f\"Context: {' '.join(contexts)}\\n\"\n",
        "        \"Answer:\\n- \"\n",
        "    )\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            max_new_tokens=180,\n",
        "            num_beams=5,\n",
        "            no_repeat_ngram_size=3,\n",
        "            length_penalty=1.2,\n",
        "            early_stopping=True\n",
        "        )\n",
        "    ans = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "    # keep bullet list clean\n",
        "    ans = \"\\n\".join(line for line in ans.splitlines() if line.strip())\n",
        "    return {\"query\": query, \"contexts\": contexts, \"answer\": ans}\n",
        "\n",
        "\n",
        "# ---------- 6) DEMO ----------\n",
        "demo_query = \"What are the symptoms of diabetes?\"\n",
        "result = answer_query(demo_query, top_k=TOP_K)\n",
        "\n",
        "print(\"\\n=== RESULT ===\")\n",
        "print(f\"Query: {result['query']}\")\n",
        "print(f\"Top-{TOP_K} Retrieved Context(s):\")\n",
        "for i, c in enumerate(result[\"contexts\"], 1):\n",
        "    print(f\"  [{i}] {c[:300]}{'...' if len(c) > 300 else ''}\")\n",
        "print(f\"\\nGenerated Answer: {result['answer']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fummpqJjV5by",
        "outputId": "81cac35d-5618-41ff-d8e2-18eb44ded51d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "No 'context' column found. Creating it from the 'answer' column.\n",
            "Saved dataset with 'context'  /content/drive/MyDrive/medquad_with_context.csv (rows: 16412)\n",
            "Loaded FAISS index from /content/drive/MyDrive/context.index (ntotal=16412)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== RESULT ===\n",
            "Query: What are the symptoms of diabetes?\n",
            "Top-3 Retrieved Context(s):\n",
            "  [1] The signs and symptoms of diabetes are\n",
            "                \n",
            "- being very thirsty  - urinating often  - feeling very hungry  - feeling very tired  - losing weight without trying  - sores that heal slowly  - dry, itchy skin  - feelings of pins and needles in your feet  - losing feeling in your feet  - blu...\n",
            "  [2] Many people with diabetes experience one or more symptoms, including extreme thirst or hunger, a frequent need to urinate and/or fatigue. Some lose weight without trying. Additional signs include sores that heal slowly, dry, itchy skin, loss of feeling or tingling in the feet and blurry eyesight. So...\n",
            "  [3] Diabetes is often called a \"silent\" disease because it can cause serious complications even before you have symptoms. Symptoms can also be so mild that you dont notice them. An estimated 8 million people in the United States have type 2 diabetes and dont know it, according to 2012 estimates by the C...\n",
            "\n",
            "Generated Answer: being very thirsty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# RAG: Build/Load FAISS + Generate with T5\n",
        "# ================================\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import torch\n",
        "from typing import List, Tuple\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "CSV_IN         = \"/content/drive/MyDrive/medquad.csv\"                 # original dataset\n",
        "CSV_WITH_CTX   = \"/content/drive/MyDrive/medquad_with_context.csv\"    # output with 'context'\n",
        "INDEX_PATH     = \"/content/drive/MyDrive/context.index\"               # FAISS index path\n",
        "\n",
        "# Public model (no auth needed). Use \"t5-small\" for faster CPU testing.\n",
        "MODEL_ID       = \"google/flan-t5-base\"\n",
        "\n",
        "# Retrieval / generation\n",
        "TOP_K          = 3\n",
        "MAX_NEW_TOKENS = 150\n",
        "NUM_BEAMS      = 5\n",
        "\n",
        "# Token budget for T5 (hard limit ~512). Keep margin for prompt & special tokens.\n",
        "MAX_INPUT_TOKENS = 512\n",
        "TOKEN_MARGIN     = 48   # leave headroom for prompt/meta\n",
        "\n",
        "# ---------- DEVICE ----------\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ---------- 1) DATA: ensure 'context' ----------\n",
        "def ensure_context(csv_in: str, csv_out: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_in)\n",
        "    if 'context' not in df.columns:\n",
        "        print(\"No 'context' column found. Creating it from the 'answer' column.\")\n",
        "        if 'answer' not in df.columns:\n",
        "            raise ValueError(\"Dataset must have an 'answer' column to create 'context'.\")\n",
        "        df['context'] = df['answer'].astype(str)\n",
        "    else:\n",
        "        df['context'] = df['context'].astype(str)\n",
        "    df.to_csv(csv_out, index=False)\n",
        "    print(f\"Saved dataset with 'context'  {csv_out} (rows: {len(df)})\")\n",
        "    return df\n",
        "\n",
        "df = ensure_context(CSV_IN, CSV_WITH_CTX)\n",
        "\n",
        "# ---------- 2) EMBEDDING MODEL ----------\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# ---------- 3) FAISS INDEX (build IP/cosine; load existing if present) ----------\n",
        "def build_faiss_index(texts: List[str], index_path: str) -> faiss.Index:\n",
        "    emb = embedder.encode(\n",
        "        texts,\n",
        "        batch_size=64,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True,  # cosine ready\n",
        "        show_progress_bar=True\n",
        "    ).astype(\"float32\")\n",
        "    d = emb.shape[1]\n",
        "    index = faiss.IndexFlatIP(d)  # inner product == cosine on unit vectors\n",
        "    index.add(np.ascontiguousarray(emb))\n",
        "    faiss.write_index(index, index_path)\n",
        "    print(f\"Built & saved FAISS index ({index.ntotal} vectors, dim={d})  {index_path}\")\n",
        "    return index\n",
        "\n",
        "def load_or_build_index(index_path: str, texts: List[str]) -> faiss.Index:\n",
        "    if os.path.exists(index_path):\n",
        "        index = faiss.read_index(index_path)\n",
        "        try:\n",
        "            metric = getattr(index, \"metric_type\", None)\n",
        "            metric_name = \"IP\" if metric == faiss.METRIC_INNER_PRODUCT else \"L2\"\n",
        "        except Exception:\n",
        "            metric_name = \"unknown\"\n",
        "        print(f\"Loaded FAISS index from {index_path} (ntotal={index.ntotal}, metric={metric_name})\")\n",
        "        return index\n",
        "    else:\n",
        "        return build_faiss_index(texts, index_path)\n",
        "\n",
        "index = load_or_build_index(INDEX_PATH, df[\"context\"].tolist())\n",
        "\n",
        "# ---------- 4) RETRIEVAL ----------\n",
        "def _maybe_normalize_query_for_ip(qv: np.ndarray, index: faiss.Index) -> np.ndarray:\n",
        "    metric_type = getattr(index, \"metric_type\", None)\n",
        "    if metric_type == faiss.METRIC_INNER_PRODUCT:\n",
        "        qv = qv.copy()\n",
        "        faiss.normalize_L2(qv)\n",
        "    return qv\n",
        "\n",
        "def retrieve(query: str, index: faiss.Index, df: pd.DataFrame, top_k: int = 3) -> List[Tuple[int, float, str]]:\n",
        "    # Encode query\n",
        "    qv = embedder.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
        "    qv = np.ascontiguousarray(qv)\n",
        "    qv = _maybe_normalize_query_for_ip(qv, index)\n",
        "\n",
        "    distances, idxs = index.search(qv, top_k)\n",
        "    out = []\n",
        "    for j, i in enumerate(idxs[0]):\n",
        "        if 0 <= i < len(df):\n",
        "            out.append((int(i), float(distances[0][j]), df.iloc[i][\"context\"]))\n",
        "    return out\n",
        "\n",
        "# ---------- 5) TOKENIZER + MODEL ----------\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_ID, legacy=False)\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_ID).to(device)\n",
        "model.eval()\n",
        "\n",
        "# ---------- 6) CONTEXT PREP: keep bullets & compact ----------\n",
        "BULLET_PATTERN = re.compile(r\"^\\s*([-\\*\\u2022]|(\\d+[\\.\\)]))\\s+\", re.UNICODE)\n",
        "\n",
        "def keep_bullets_or_compact(text: str, max_lines: int = 20, max_chars: int = 800) -> str:\n",
        "    \"\"\"Prefer bullet lines; otherwise return a compact snippet.\"\"\"\n",
        "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
        "    bullet_lines = [ln for ln in lines if BULLET_PATTERN.match(ln) or \" - \" in ln]\n",
        "    chosen = bullet_lines if bullet_lines else lines\n",
        "    snippet = \"\\n\".join(chosen[:max_lines])\n",
        "    if len(snippet) > max_chars:\n",
        "        snippet = snippet[:max_chars].rsplit(\" \", 1)[0] + \"...\"\n",
        "    return snippet\n",
        "\n",
        "def pack_contexts_for_budget(\n",
        "    question: str,\n",
        "    contexts: List[str],\n",
        "    max_input_tokens: int = MAX_INPUT_TOKENS,\n",
        "    token_margin: int = TOKEN_MARGIN\n",
        ") -> str:\n",
        "    \"\"\"Pack as many preprocessed contexts as fit under the tokenizer budget.\"\"\"\n",
        "    header = (\n",
        "        \"You are a concise medical assistant.\\n\"\n",
        "        \"Using ONLY the context, list the common symptoms of diabetes as bullet points.\\n\"\n",
        "        \"If something isn't in the context, do not include it.\\n\"\n",
        "        f\"Question: {question}\\n\"\n",
        "        \"Context:\\n\"\n",
        "    )\n",
        "    # Token budget for contexts only\n",
        "    header_ids = tokenizer.encode(header, add_special_tokens=False)\n",
        "    remaining = max(8, max_input_tokens - token_margin - len(header_ids))\n",
        "\n",
        "    packed_contexts: List[str] = []\n",
        "    used = 0\n",
        "    for ctx in contexts:\n",
        "        processed = keep_bullets_or_compact(ctx)\n",
        "        ids = tokenizer.encode(processed + \"\\n\", add_special_tokens=False)\n",
        "        if used + len(ids) <= remaining:\n",
        "            packed_contexts.append(processed)\n",
        "            used += len(ids)\n",
        "        else:\n",
        "            # Try a smaller slice of this context\n",
        "            shortened = keep_bullets_or_compact(ctx, max_lines=10, max_chars=400)\n",
        "            ids2 = tokenizer.encode(shortened + \"\\n\", add_special_tokens=False)\n",
        "            if used + len(ids2) <= remaining:\n",
        "                packed_contexts.append(shortened)\n",
        "                used += len(ids2)\n",
        "            # else skip it\n",
        "    body = \"\\n\".join(packed_contexts)\n",
        "    prompt = header + body + \"\\nAnswer:\\n- \"\n",
        "    return prompt\n",
        "\n",
        "# ---------- 7) QA FUNCTION ----------\n",
        "def answer_query(question: str, top_k: int = TOP_K) -> dict:\n",
        "    hits = retrieve(question, index, df, top_k=top_k)\n",
        "    contexts = [h[2] for h in hits]  # texts only\n",
        "    prompt = pack_contexts_for_budget(question, contexts, MAX_INPUT_TOKENS, TOKEN_MARGIN)\n",
        "\n",
        "    # Final safety: enforce truncation in case\n",
        "    input_ids = tokenizer.encode(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=MAX_INPUT_TOKENS\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            max_new_tokens=MAX_NEW_TOKENS,\n",
        "            num_beams=NUM_BEAMS,\n",
        "            no_repeat_ngram_size=3,\n",
        "            length_penalty=1.2,\n",
        "            early_stopping=True,\n",
        "        )\n",
        "    ans = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "    # Clean bullet list\n",
        "    ans = \"\\n\".join(line for line in ans.splitlines() if line.strip())\n",
        "\n",
        "    return {\n",
        "        \"query\": question,\n",
        "        \"hits\": hits,\n",
        "        \"answer\": ans,\n",
        "        \"prompt_tokens\": int(input_ids.shape[1]),\n",
        "    }\n",
        "\n",
        "# ---------- 8) DEMO ----------\n",
        "demo_question = \"What are the symptoms of diabetes?\"\n",
        "result = answer_query(demo_question, top_k=TOP_K)\n",
        "\n",
        "print(\"\\n=== RESULT ===\")\n",
        "print(f\"Query: {result['query']}\")\n",
        "print(f\"Prompt tokens used: {result['prompt_tokens']} / {MAX_INPUT_TOKENS}\")\n",
        "print(f\"Top-{TOP_K} Retrieved Context(s):\")\n",
        "for rank, (row_idx, score, text) in enumerate(result[\"hits\"], 1):\n",
        "    snippet = text[:300] + (\"...\" if len(text) > 300 else \"\")\n",
        "    print(f\"  [{rank}] row={row_idx} score={score:.4f}  {snippet}\")\n",
        "print(\"\\nGenerated Answer:\")\n",
        "print(result[\"answer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPkcMHoUXwy-",
        "outputId": "7b10390e-9c84-4ddc-cf43-22d74a351687"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "No 'context' column found. Creating it from the 'answer' column.\n",
            "Saved dataset with 'context'  /content/drive/MyDrive/medquad_with_context.csv (rows: 16412)\n",
            "Loaded FAISS index from /content/drive/MyDrive/context.index (ntotal=16412, metric=L2)\n",
            "\n",
            "=== RESULT ===\n",
            "Query: What are the symptoms of diabetes?\n",
            "Prompt tokens used: 384 / 512\n",
            "Top-3 Retrieved Context(s):\n",
            "  [1] row=16214 score=0.4028  The signs and symptoms of diabetes are\n",
            "                \n",
            "- being very thirsty  - urinating often  - feeling very hungry  - feeling very tired  - losing weight without trying  - sores that heal slowly  - dry, itchy skin  - feelings of pins and needles in your feet  - losing feeling in your feet  - blu...\n",
            "  [2] row=112 score=0.4611  Many people with diabetes experience one or more symptoms, including extreme thirst or hunger, a frequent need to urinate and/or fatigue. Some lose weight without trying. Additional signs include sores that heal slowly, dry, itchy skin, loss of feeling or tingling in the feet and blurry eyesight. So...\n",
            "  [3] row=106 score=0.4921  Diabetes is often called a \"silent\" disease because it can cause serious complications even before you have symptoms. Symptoms can also be so mild that you dont notice them. An estimated 8 million people in the United States have type 2 diabetes and dont know it, according to 2012 estimates by the C...\n",
            "\n",
            "Generated Answer:\n",
            "being very thirsty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Improvement of the above code\n",
        "\n",
        "# ==========================================================\n",
        "# RAG with FAISS + Sentence-Transformers + T5 (robust output)\n",
        "# ==========================================================\n",
        "# If needed in a fresh Colab:\n",
        "# !pip install -q faiss-cpu sentence-transformers transformers\n",
        "\n",
        "import os, re\n",
        "from typing import List, Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "CSV_IN         = \"/content/drive/MyDrive/medquad.csv\"                 # original dataset\n",
        "CSV_WITH_CTX   = \"/content/drive/MyDrive/medquad_with_context.csv\"    # dataset with 'context'\n",
        "INDEX_PATH     = \"/content/drive/MyDrive/context.index\"               # FAISS index path\n",
        "\n",
        "# Public model (no auth needed). Use \"t5-small\" for faster CPU tests.\n",
        "MODEL_ID       = \"google/flan-t5-base\"\n",
        "\n",
        "TOP_K          = 3\n",
        "MAX_NEW_TOKENS = 150\n",
        "MIN_NEW_TOKENS = 60     # avoid ultra-short answers\n",
        "NUM_BEAMS      = 4\n",
        "\n",
        "# T5 input budget (hard limit ~512)\n",
        "MAX_INPUT_TOKENS = 512\n",
        "TOKEN_MARGIN     = 48    # reserve for prompt/special tokens\n",
        "\n",
        "# ---------------- DEVICE ----------------\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ---------------- 1) DATA ----------------\n",
        "def ensure_context(csv_in: str, csv_out: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_in)\n",
        "    if \"context\" not in df.columns:\n",
        "        print(\"No 'context' column found. Creating it from the 'answer' column.\")\n",
        "        if \"answer\" not in df.columns:\n",
        "            raise ValueError(\"Dataset must have an 'answer' column to create 'context'.\")\n",
        "        df[\"context\"] = df[\"answer\"].astype(str)\n",
        "    else:\n",
        "        df[\"context\"] = df[\"context\"].astype(str)\n",
        "    df.to_csv(csv_out, index=False)\n",
        "    print(f\"Saved dataset with 'context'  {csv_out} (rows: {len(df)})\")\n",
        "    return df\n",
        "\n",
        "df = ensure_context(CSV_IN, CSV_WITH_CTX)\n",
        "\n",
        "# ---------------- 2) EMBEDDINGS ----------------\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# ---------------- 3) FAISS INDEX ----------------\n",
        "def build_faiss_index(texts: List[str], index_path: str) -> faiss.Index:\n",
        "    emb = embedder.encode(\n",
        "        texts,\n",
        "        batch_size=64,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True,  # cosine-ready (unit vectors)\n",
        "        show_progress_bar=True\n",
        "    ).astype(\"float32\")\n",
        "    d = emb.shape[1]\n",
        "    index = faiss.IndexFlatIP(d)    # inner product == cosine on unit vectors\n",
        "    index.add(np.ascontiguousarray(emb))\n",
        "    faiss.write_index(index, index_path)\n",
        "    print(f\"Built & saved FAISS index ({index.ntotal} vectors, dim={d})  {index_path}\")\n",
        "    return index\n",
        "\n",
        "def load_or_build_index(index_path: str, texts: List[str]) -> faiss.Index:\n",
        "    if os.path.exists(index_path):\n",
        "        index = faiss.read_index(index_path)\n",
        "        try:\n",
        "            metric = getattr(index, \"metric_type\", None)\n",
        "            metric_name = \"IP\" if metric == faiss.METRIC_INNER_PRODUCT else \"L2\"\n",
        "        except Exception:\n",
        "            metric_name = \"unknown\"\n",
        "        print(f\"Loaded FAISS index from {index_path} (ntotal={index.ntotal}, metric={metric_name})\")\n",
        "        return index\n",
        "    else:\n",
        "        return build_faiss_index(texts, index_path)\n",
        "\n",
        "index = load_or_build_index(INDEX_PATH, df[\"context\"].tolist())\n",
        "\n",
        "# ---------------- 4) RETRIEVAL ----------------\n",
        "def _maybe_normalize_query_for_ip(qv: np.ndarray, index: faiss.Index) -> np.ndarray:\n",
        "    metric_type = getattr(index, \"metric_type\", None)\n",
        "    if metric_type == faiss.METRIC_INNER_PRODUCT:\n",
        "        qv = qv.copy()\n",
        "        faiss.normalize_L2(qv)\n",
        "    return qv\n",
        "\n",
        "def retrieve(query: str, index: faiss.Index, df: pd.DataFrame, top_k: int = 3) -> List[Tuple[int, float, str]]:\n",
        "    qv = embedder.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
        "    qv = np.ascontiguousarray(qv)\n",
        "    qv = _maybe_normalize_query_for_ip(qv, index)\n",
        "    distances, idxs = index.search(qv, top_k)\n",
        "    out = []\n",
        "    for j, i in enumerate(idxs[0]):\n",
        "        if 0 <= i < len(df):\n",
        "            out.append((int(i), float(distances[0][j]), df.iloc[i][\"context\"]))\n",
        "    return out\n",
        "\n",
        "# ---------------- 5) MODEL ----------------\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_ID, legacy=False)\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_ID).to(device)\n",
        "model.eval()\n",
        "\n",
        "# ---------------- 6) CONTEXT PACKING ----------------\n",
        "BULLET_PATTERN = re.compile(r\"^\\s*([-\\*\\u2022]|(\\d+[\\.\\)]))\\s+\", re.UNICODE)\n",
        "\n",
        "def keep_bullets_or_compact(text: str, max_lines: int = 20, max_chars: int = 800) -> str:\n",
        "    \"\"\"Prefer bullet lines; otherwise compact snippet.\"\"\"\n",
        "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
        "    bullet_lines = [ln for ln in lines if BULLET_PATTERN.match(ln) or \" - \" in ln]\n",
        "    chosen = bullet_lines if bullet_lines else lines\n",
        "    snippet = \"\\n\".join(chosen[:max_lines])\n",
        "    if len(snippet) > max_chars:\n",
        "        snippet = snippet[:max_chars].rsplit(\" \", 1)[0] + \"...\"\n",
        "    return snippet\n",
        "\n",
        "def pack_contexts_for_budget(question: str, contexts: List[str]) -> str:\n",
        "    # Generic instruction suitable for lists (symptoms/causes/etc.)\n",
        "    header = (\n",
        "        \"You are a concise medical assistant.\\n\"\n",
        "        \"Using ONLY the context, answer the question as bullet points.\\n\"\n",
        "        \"If the answer is a list (e.g., symptoms/causes/treatments), return one item per line.\\n\"\n",
        "        \"Return ONLY bullet points; do not add extra text.\\n\"\n",
        "        f\"Question: {question}\\n\"\n",
        "        \"Context:\\n\"\n",
        "    )\n",
        "    header_ids = tokenizer.encode(header, add_special_tokens=False)\n",
        "    remaining = max(8, MAX_INPUT_TOKENS - TOKEN_MARGIN - len(header_ids))\n",
        "\n",
        "    packed, used = [], 0\n",
        "    for ctx in contexts:\n",
        "        processed = keep_bullets_or_compact(ctx)\n",
        "        ids = tokenizer.encode(processed + \"\\n\", add_special_tokens=False)\n",
        "        if used + len(ids) <= remaining:\n",
        "            packed.append(processed)\n",
        "            used += len(ids)\n",
        "        else:\n",
        "            shortened = keep_bullets_or_compact(ctx, max_lines=10, max_chars=400)\n",
        "            ids2 = tokenizer.encode(shortened + \"\\n\", add_special_tokens=False)\n",
        "            if used + len(ids2) <= remaining:\n",
        "                packed.append(shortened)\n",
        "                used += len(ids2)\n",
        "    body = \"\\n\".join(packed)\n",
        "    return header + body + \"\\nAnswer:\\n- \"\n",
        "\n",
        "# ---------------- 7) PARSERS & FALLBACK ----------------\n",
        "def parse_bullets(text: str, max_items: int = 20) -> list[str]:\n",
        "    \"\"\"\n",
        "    Extract bullet items from model text. Handles lines like\n",
        "    '- a - b - c' (inline bullets) and standard bullet lines.\n",
        "    Deduplicates and trims.\n",
        "    \"\"\"\n",
        "    items = []\n",
        "\n",
        "    def add_item(s: str):\n",
        "        s = s.strip()\n",
        "        s = re.sub(r\"^([-\\*\\u2022]|\\d+[\\.\\)])\\s*\", \"\", s)  # strip bullet/number\n",
        "        s = re.sub(r\"\\s+\", \" \", s).strip(\" .;:-\").strip()\n",
        "        if s:\n",
        "            items.append(s)\n",
        "\n",
        "    for raw in text.splitlines():\n",
        "        line = raw.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        if re.search(r\"\\s-\\s\", line):\n",
        "            chunks = [c for c in re.split(r\"\\s-\\s\", line) if c.strip()]\n",
        "            if not line.lstrip().startswith((\"-\", \"\", \"*\")) and len(chunks) > 1:\n",
        "                chunks = chunks[1:]  # drop preamble\n",
        "            for ch in chunks:\n",
        "                add_item(ch)\n",
        "            continue\n",
        "\n",
        "        if BULLET_PATTERN.match(line) or line.lstrip().startswith((\"-\", \"\", \"*\")):\n",
        "            add_item(line)\n",
        "\n",
        "    seen, uniq = set(), []\n",
        "    for it in items:\n",
        "        key = re.sub(r\"[^a-z0-9]+\", \" \", it.lower()).strip()\n",
        "        if key and key not in seen:\n",
        "            seen.add(key)\n",
        "            uniq.append(it)\n",
        "            if len(uniq) >= max_items:\n",
        "                break\n",
        "    return uniq\n",
        "\n",
        "def extract_bullets_from_contexts(contexts: List[str]) -> str:\n",
        "    raw_lines = []\n",
        "    for ctx in contexts:\n",
        "        for ln in ctx.splitlines():\n",
        "            ln = ln.strip()\n",
        "            if not ln:\n",
        "                continue\n",
        "            if BULLET_PATTERN.match(ln) or \" - \" in ln:\n",
        "                ln = re.sub(r\"\\s*-\\s*\", \" - \", ln).strip()\n",
        "                ln = re.sub(r\"^([-\\*\\u2022]|\\d+[\\.\\)])\\s*\", \"\", ln).strip()\n",
        "                raw_lines.append(ln)\n",
        "    seen, uniq = set(), []\n",
        "    for ln in raw_lines:\n",
        "        key = re.sub(r\"[^a-z0-9]+\", \" \", ln.lower()).strip()\n",
        "        if key and key not in seen:\n",
        "            seen.add(key)\n",
        "            uniq.append(ln)\n",
        "    return \"\" if not uniq else \"- \" + \"\\n- \".join(uniq)\n",
        "\n",
        "# ---------------- 8) QA ----------------\n",
        "def answer_query(question: str, top_k: int = TOP_K) -> dict:\n",
        "    hits = retrieve(question, index, df, top_k=top_k)\n",
        "    contexts = [h[2] for h in hits]\n",
        "\n",
        "    prompt = pack_contexts_for_budget(question, contexts)\n",
        "    input_ids = tokenizer.encode(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=MAX_INPUT_TOKENS\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            max_new_tokens=MAX_NEW_TOKENS,\n",
        "            min_new_tokens=MIN_NEW_TOKENS,\n",
        "            num_beams=NUM_BEAMS,\n",
        "            no_repeat_ngram_size=3,\n",
        "            length_penalty=1.0,\n",
        "            early_stopping=False,\n",
        "        )\n",
        "    raw = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "\n",
        "    # Prefer the model's bullets\n",
        "    bullets = parse_bullets(raw, max_items=20)\n",
        "\n",
        "    # Fallback to deterministic extraction if model is too terse\n",
        "    if len(bullets) < 3:\n",
        "        fallback = extract_bullets_from_contexts(contexts)\n",
        "        final = fallback if fallback else \"- \" + \"\\n- \".join([ln for ln in raw.splitlines() if ln.strip()][:10])\n",
        "    else:\n",
        "        final = \"- \" + \"\\n- \".join(bullets[:12])\n",
        "\n",
        "    return {\n",
        "        \"query\": question,\n",
        "        \"hits\": hits,\n",
        "        \"answer\": final,\n",
        "        \"prompt_tokens\": int(input_ids.shape[1]),\n",
        "    }\n",
        "\n",
        "# ---------------- 9) DEMO ----------------\n",
        "demo_question = \"What are the symptoms of diabetes?\"\n",
        "result = answer_query(demo_question, top_k=TOP_K)\n",
        "\n",
        "print(\"\\n=== RESULT ===\")\n",
        "print(f\"Query: {result['query']}\")\n",
        "print(f\"Prompt tokens used: {result['prompt_tokens']} / {MAX_INPUT_TOKENS}\")\n",
        "print(f\"Top-{TOP_K} Retrieved Context(s):\")\n",
        "for rank, (row_idx, score, text) in enumerate(result[\"hits\"], 1):\n",
        "    snippet = text[:300] + (\"...\" if len(text) > 300 else \"\")\n",
        "    print(f\"  [{rank}] row={row_idx} score={score:.4f}  {snippet}\")\n",
        "print(\"\\nGenerated Answer:\\n\" + result[\"answer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OazTMsXZnm6",
        "outputId": "a4c1345a-3779-45cc-b1df-5e7b406ae93b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "No 'context' column found. Creating it from the 'answer' column.\n",
            "Saved dataset with 'context'  /content/drive/MyDrive/medquad_with_context.csv (rows: 16412)\n",
            "Loaded FAISS index from /content/drive/MyDrive/context.index (ntotal=16412, metric=L2)\n",
            "\n",
            "=== RESULT ===\n",
            "Query: What are the symptoms of diabetes?\n",
            "Prompt tokens used: 405 / 512\n",
            "Top-3 Retrieved Context(s):\n",
            "  [1] row=16214 score=0.4028  The signs and symptoms of diabetes are\n",
            "                \n",
            "- being very thirsty  - urinating often  - feeling very hungry  - feeling very tired  - losing weight without trying  - sores that heal slowly  - dry, itchy skin  - feelings of pins and needles in your feet  - losing feeling in your feet  - blu...\n",
            "  [2] row=112 score=0.4611  Many people with diabetes experience one or more symptoms, including extreme thirst or hunger, a frequent need to urinate and/or fatigue. Some lose weight without trying. Additional signs include sores that heal slowly, dry, itchy skin, loss of feeling or tingling in the feet and blurry eyesight. So...\n",
            "  [3] row=106 score=0.4921  Diabetes is often called a \"silent\" disease because it can cause serious complications even before you have symptoms. Symptoms can also be so mild that you dont notice them. An estimated 8 million people in the United States have type 2 diabetes and dont know it, according to 2012 estimates by the C...\n",
            "\n",
            "Generated Answer:\n",
            "- frequent urination\n",
            "- feeling very hungry or tired\n",
            "- losing weight without trying\n",
            "- sores that heal slowly\n",
            "- drying, itchy skin\n",
            "- loss of feeling or tingling in the feet\n",
            "- having blurry eyesight. being very watery , frequent urinate\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOc3fZI+q7OONnPUIJPfra4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}